#!/usr/bin/env python3
# coding: utf-8
"""
å¼‚æ­¥æ—¥å¿—æŠ“å–è„šæœ¬ï¼ˆä¸»çº¿ç¨‹åŠ¨æ€è°ƒåº¦ + ä»çº¿ç¨‹æš‚åœæ¢å¤æœºåˆ¶ï¼‰
æ”¯æŒï¼š
  - æ­£æ•°å‚æ•° Nï¼šæœ€è¿‘ N å¤©ï¼ˆåŒ…å«ä»Šå¤©ï¼‰
  - è´Ÿæ•°å‚æ•° -Nï¼šN å¤©å‰å½“å¤©
ç¯å¢ƒå˜é‡ï¼š
  - ACCOUNTS_JSON: JSON å­—ç¬¦ä¸²ï¼Œå½¢å¦‚ {"acctid1": "service1", ...}
  - CF_COOKIE: Cloudflare cookie å­—ç¬¦ä¸²
ç”¨æ³•ï¼š
  python fetcher.py 7          # æŸ¥è¯¢æœ€è¿‘7å¤©ï¼ˆåŒ…å«ä»Šå¤©ï¼‰
  python fetcher.py -2         # æŸ¥è¯¢2å¤©å‰å½“å¤©
  python fetcher.py 20251101   # æŒ‡å®šæŸå¤© YYYYMMDD
  python fetcher.py -<account_id> 7  # ä¹Ÿæ”¯æŒ -<account_id> é€‰æ‹©ç‰¹å®šè´¦æˆ·
"""

import os, sys, json, copy, asyncio, aiohttp, contextlib
from datetime import datetime, timedelta, timezone

# ===================== é…ç½®åŒº =====================
SEGMENTS_PER_DAY = 24
MAX_CONCURRENT_ACCOUNTS = 1
FOLLOWER_START_INTERVAL = 3
FOLLOWER_RECOVERY_INTERVAL = 3
# ===================================================

ACCOUNTS_JSON = os.getenv("ACCOUNTS_JSON")
if not ACCOUNTS_JSON:
    print("âŒ æœªæ£€æµ‹åˆ°ç¯å¢ƒå˜é‡ ACCOUNTS_JSON")
    sys.exit(1)
try:
    ACCOUNTS = json.loads(ACCOUNTS_JSON)
    if not isinstance(ACCOUNTS, dict):
        raise ValueError("ACCOUNTS_JSON must be a JSON object")
except Exception as e:
    print("âŒ ACCOUNTS_JSON å†…å®¹æ— æ•ˆï¼š", e)
    sys.exit(1)

CF_COOKIE = os.getenv("CF_COOKIE") or ""
if not CF_COOKIE or len(CF_COOKIE) < 20:
    print("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆ CF_COOKIE")
    sys.exit(1)

URL_TEMPLATE = "https://dash.cloudflare.com/api/v4/accounts/{account_id}/workers/observability/telemetry/query"
HEADERS = {
    "accept": "*/*",
    "content-type": "application/json",
    "origin": "https://dash.cloudflare.com",
    "referer": "https://dash.cloudflare.com/",
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "workers-observability-origin": "workers-logs",
    "x-cross-site-security": "dash",
    "cookie": CF_COOKIE,
}

# ===================== å·¥å…·å‡½æ•° =====================
def get_date_list(arg: str):
    """è§£æå‚æ•°ï¼Œæ”¯æŒæ­£æ•°æŸ¥è¯¢æœ€è¿‘Nå¤©ï¼Œè´Ÿæ•°æŸ¥è¯¢Nå¤©å‰å½“å¤©"""
    today = datetime.now(timezone.utc).date()
    if arg and arg.isdigit() and len(arg) == 8:
        return [arg]  # æŒ‡å®šæ—¥æœŸ YYYYMMDD
    try:
        n = int(arg)
    except:
        n = 7

    if n >= 0:
        # æœ€è¿‘ N å¤©ï¼ŒåŒ…æ‹¬ä»Šå¤©
        return [(today - timedelta(days=i)).strftime("%Y%m%d") for i in range(n)]
    else:
        # N å¤©å‰å½“å¤©
        target = today + timedelta(days=n)
        return [target.strftime("%Y%m%d")]

def split_timeframes(date_str, segments=SEGMENTS_PER_DAY):
    dt = datetime.strptime(date_str, "%Y%m%d")
    start = datetime(dt.year, dt.month, dt.day, 0, 0, 0, tzinfo=timezone.utc)
    end = start + timedelta(days=1) - timedelta(milliseconds=1)
    start_ms = int(start.timestamp() * 1000)
    end_ms = int(end.timestamp() * 1000)
    step = (end_ms - start_ms) // segments
    arr = []
    for i in range(segments):
        s = start_ms + i * step
        e = s + step if i < segments - 1 else end_ms
        arr.append((s, e))
    return arr

def linear_delay(attempt: int):
    return min(0.5 * attempt, 10.0)

# ===================== å¼‚æ­¥æŠ“å–å‡½æ•° =====================
async def fetch_segment(session, account_id, service_name, segment, main_ok_event: asyncio.Event = None, is_main=False):
    all_logs = segment.get("partial_logs", {})
    page = 0
    base_data = {
        "view": "invocations",
        "queryId": "workers-logs-invocations",
        "limit": 100,
        "parameters": {
            "datasets": ["cloudflare-workers"],
            "filters": [
                {"key": "$metadata.service", "type": "string", "value": service_name, "operation": "eq"}
            ],
            "calculations": [], "groupBys": [], "havings": []
        },
        "timeframe": {"from": segment["start_ms"], "to": segment["end_ms"]}
    }

    offset = segment.get("offset")
    attempt = 1
    while True:
        data = copy.deepcopy(base_data)
        if offset:
            data["offset"] = offset
        try:
            async with session.post(URL_TEMPLATE.format(account_id=account_id), headers=HEADERS, json=data, timeout=30) as resp:
                status = resp.status
                text = await resp.text()
                if status == 200:
                    if is_main and main_ok_event is not None and not main_ok_event.is_set():
                        main_ok_event.set()
                        print(f"ğŸ”” {account_id}/{service_name} ä¸»çº¿ç¨‹å·²æ¢å¤ï¼ˆHTTP 200ï¼‰")
                    try:
                        result = await resp.json()
                    except Exception as e:
                        print(f"âŒ {account_id}/{service_name} ç¬¬{segment['seg_id']}æ®µ JSON è§£ç å¼‚å¸¸: {e}")
                        result = None
                    if not result or "result" not in result or "invocations" not in result["result"]:
                        print(f"âŒ {account_id}/{service_name} ç¬¬{segment['seg_id']}æ®µ æ”¶åˆ°ç©ºæˆ–å¼‚å¸¸å“åº”ç»“æ„")
                        break
                    invocations = result["result"].get("invocations", {})
                    new_entries = 0
                    for req_id, entries in invocations.items():
                        if req_id not in all_logs:
                            all_logs[req_id] = entries
                            new_entries += len(entries)
                    if new_entries == 0 and not offset:
                        break
                    page += 1
                    print(f"âœ… {account_id}/{service_name} ç¬¬{segment['seg_id']}æ®µ ç¬¬{page}é¡µ è·å– {new_entries} æ¡æ—¥å¿—")
                    offset = None
                    for req_id in reversed(list(invocations.keys())):
                        logs_list = invocations[req_id]
                        if isinstance(logs_list, list) and logs_list:
                            metadata = logs_list[-1].get("$metadata", {})
                            offset = metadata.get("id")
                            if offset:
                                break
                    if not offset:
                        break
                    attempt = 1
                elif status == 429:
                    if is_main and main_ok_event is not None:
                        if main_ok_event.is_set():
                            main_ok_event.clear()
                            print(f"â›” {account_id}/{service_name} ä¸»çº¿ç¨‹æ£€æµ‹åˆ° 429ï¼Œåˆ‡æ¢é€€é¿æ¨¡å¼")
                    else:
                        segment["status"] = "paused"
                        segment["offset"] = offset
                        segment["partial_logs"] = all_logs
                        print(f"â™»ï¸ {account_id}/{service_name} ç¬¬{segment['seg_id']}æ®µ ä»çº¿ç¨‹é‡åˆ° 429ï¼Œæš‚åœ")
                        return
                else:
                    print(f"âš ï¸ {account_id}/{service_name} ç¬¬{segment['seg_id']}æ®µ HTTP {status} {text[:200]}")
        except asyncio.CancelledError:
            raise
        except Exception as e:
            print(f"âŒ {account_id}/{service_name} ç¬¬{segment['seg_id']}æ®µ ç½‘ç»œ/è¯·æ±‚å¼‚å¸¸: {e}")

        if status != 200:
            delay = linear_delay(attempt)
            print(f"â³ {account_id}/{service_name} ç¬¬{segment['seg_id']}æ®µ ç¬¬{attempt}æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f}s")
            await asyncio.sleep(delay)
            attempt += 1

    segment["status"] = "done"
    segment["partial_logs"] = all_logs

# ===================== è´¦æˆ·æŠ“å–æµç¨‹ =====================
async def fetch_account(account_id, service_name, dates):
    async with aiohttp.ClientSession() as session:
        for date_str in dates:
            print(f"\n===== æŠ“å– {account_id}/{service_name} çš„ {date_str} æ—¥æ—¥å¿—ï¼ˆUTCï¼‰ =====")
            ranges = split_timeframes(date_str)
            segments = [
                {"seg_id": i+1, "start_ms": s, "end_ms": e, "status": "pending", "offset": None, "partial_logs": {}}
                for i, (s, e) in enumerate(ranges)
            ]
            main_ok_event = asyncio.Event()
            main_ok_event.set()
            tasks = []

            async def main_loop():
                while True:
                    pending = [seg for seg in segments if seg["status"] == "pending"]
                    paused = [seg for seg in segments if seg["status"] == "paused"]
                    if pending:
                        seg = pending[0]
                    elif paused:
                        seg = paused[0]
                        seg["status"] = "running"
                    else:
                        break
                    seg["status"] = "running"
                    await fetch_segment(session, account_id, service_name, seg, main_ok_event, is_main=True)
            
            async def follower_loop():
                follower_segments = [seg for seg in segments if seg["status"] == "pending"]
                tasks = []
                for seg in follower_segments:
                    await asyncio.sleep(FOLLOWER_START_INTERVAL)
                    t = asyncio.create_task(fetch_segment(session, account_id, service_name, seg, main_ok_event, is_main=False))
                    tasks.append(t)
                if tasks:
                    await asyncio.gather(*tasks)

            await asyncio.gather(main_loop(), follower_loop())

            all_logs = {}
            for seg in segments:
                all_logs.update(seg["partial_logs"])
            out_file = f"{account_id}_invocations_{date_str}.json"
            with open(out_file, "w", encoding="utf-8") as f:
                json.dump({"invocations": all_logs}, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“¦ {account_id} å·²ä¿å­˜ {len(all_logs)} æ¡æ—¥å¿— -> {out_file}")

# ===================== ä¸»ç¨‹åº =====================
async def main_async():
    args = sys.argv[1:]
    selected_days = None
    selected_accounts = []
    for a in args:
        if a.startswith("-") and not a[1:].isdigit():
            selected_accounts.append(a[1:])
        elif a.lstrip("-").isdigit():
            selected_days = a

    if selected_days is None:
        selected_days = "7"

    if selected_accounts:
        accounts = {k: v for k, v in ACCOUNTS.items() if k in selected_accounts}
        if not accounts:
            print("âŒ æ²¡æœ‰åŒ¹é…çš„è´¦æˆ·ID")
            return
    else:
        accounts = ACCOUNTS

    dates = get_date_list(selected_days) if len(selected_days) != 8 else [selected_days]
    print(f"ğŸ“… æŸ¥è¯¢å¤©æ•°: {dates}")
    print(f"ğŸ‘¥ ç›®æ ‡è´¦æˆ·: {', '.join(accounts.keys())}")

    account_list = list(accounts.items())
    for i in range(0, len(account_list), MAX_CONCURRENT_ACCOUNTS):
        batch = account_list[i:i + MAX_CONCURRENT_ACCOUNTS]
        tasks = [fetch_account(acc_id, svc_name, dates) for acc_id, svc_name in batch]
        await asyncio.gather(*tasks)

if __name__ == "__main__":
    asyncio.run(main_async())
