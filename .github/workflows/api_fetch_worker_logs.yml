name: Fetch sub Logs

on:
  # schedule:
    # 每天凌晨 01:00 UTC 运行一次，可根据需要修改
    # - cron: '0 1 * * *'
  workflow_dispatch: # 可以手动触发

jobs:
  fetch_logs:
    runs-on: ubuntu-latest

    env:
      CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
      CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
      WORKER_NAME: "sub"
      OUTPUT_FILE: "sub_logs.json"

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Fetch Worker logs
        run: |
          python3 <<'EOF'
          import os
          import requests
          import datetime
          import json
          from time import sleep
          
          API_TOKEN = os.getenv("CF_API_TOKEN")
          ACCOUNT_ID = os.getenv("CF_ACCOUNT_ID")
          WORKER_NAME = "sub"
          OUTPUT_FILE = "worker_logs.json"
          LIMIT = 1000
          
          # 时间范围：过去 12 天
          now = datetime.datetime.utcnow()
          since = int((now - datetime.timedelta(days=12)).timestamp())
          until = int(now.timestamp())
          
          TIMEFRAME = {
              "from": since,
              "to": until
          }
          
          API_URL = f"https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/workers/observability/telemetry/query"
          
          def query_logs(cursor=None):
              payload = {
                  "queryId": "requests",
                  "timeframe": TIMEFRAME,
                  "filters": [
                      {
                          "field": "worker.name",
                          "operator": "==",
                          "value": WORKER_NAME
                      }
                  ],
                  "limit": LIMIT
              }
              if cursor:
                  payload["cursor"] = cursor
          
              headers = {
                  "Authorization": f"Bearer {API_TOKEN}",
                  "Content-Type": "application/json"
              }
          
              resp = requests.post(API_URL, headers=headers, json=payload)
              if resp.status_code != 200:
                  raise Exception(f"API请求失败 {resp.status_code}: {resp.text}")
              return resp.json()
          
          # 拉取全部日志
          all_logs = []
          cursor = None
          while True:
              data = query_logs(cursor)
              events = data.get("result", {}).get("events", [])
              all_logs.extend(events)
          
              cursor = data.get("result", {}).get("next_cursor")
              if not cursor:
                  break
              sleep(0.5)
          
          # 保存 JSON 文件
          with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
              json.dump(all_logs, f, ensure_ascii=False, indent=2)
          
          print(f"共拉取日志条数: {len(all_logs)}")
          print(f"已保存到 {OUTPUT_FILE}")
          EOF

      - name: Upload logs as artifact
        uses: actions/upload-artifact@v4
        with:
          name: worker_logs
          path: worker_logs.json
